{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aaeafaf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "import numpy as np\n",
    "import re\n",
    "import json\n",
    "from datetime import datetime, timedelta\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb96a16",
   "metadata": {},
   "source": [
    "### Scraper\n",
    "\n",
    "*The scraper Loops through rightmove results pages of 5 London areas extracting link, price and featured property status of each property*\n",
    "\n",
    "\n",
    "**What areas?**\n",
    "\n",
    "5 relevant, non-overlapping areas defined by a 1 mile (or 0.5 mile) radius around the following tube stations (also see screenshot below):\n",
    "- Kentish Town (1 mile)\n",
    "- Royal Oak (1 mile)\n",
    "- Finchley Road (1 mile)\n",
    "- Angel (1 mile)\n",
    "- Mornington Crescent (0.5 miles)\n",
    "\n",
    "\n",
    "**What search criteria are used?**\n",
    "\n",
    "I specify that properties must:\n",
    "- have exactly 2 bedrooms and be a house/flat/apartment to ensure we compare like with like\n",
    "- have been posted in last 7 days to ensure they don't appear in last week's scrape\n",
    "\n",
    "\n",
    "**Why are there two scrapers?**\n",
    "\n",
    "The first scraper loops through the 4 stations with 1mile radii. Due to the much lower number of properties in 0.5 miles around Mornington Crescent, results rarely go onto a second page meaning. Therefore I simply created a specific scraping code for it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64f1cc9d",
   "metadata": {},
   "source": [
    "![alt text](Areas.png \"Areas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "aacd6953",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping the rightmove property search results webpages \n",
    "# Collates valid properties' weblinks, plus their price and id\n",
    "\n",
    "def scrape_results_page(min_beds=2,max_beds=2,radius=1,noPages=2,days_since_added=7):\n",
    "    all_apartment_links = [] # stores apartment links\n",
    "    all_price = [] # stores the listing price of apartment\n",
    "    all_featured = []\n",
    "    all_datetime = []\n",
    "    stations = ['STATION%5E7832','STATION%5E3509', 'STATION%5E9338', 'STATION%5E245']\n",
    "    \n",
    "    ## Main scraper for 1 mile radius stations\n",
    "    \n",
    "    for station in stations:\n",
    "        for i in range(noPages):\n",
    "            if i==0:\n",
    "                r= requests.get(f'https://www.rightmove.co.uk/property-for-sale/find.html?locationIdentifier={station}&maxBedrooms={max_beds}&minBedrooms={min_beds}&radius={radius}&sortType=6&propertyTypes=detached%2Cflat%2Csemi-detached%2Cterraced&maxDaysSinceAdded={days_since_added}&includeSSTC=false&mustHave=&dontShow=&furnishTypes=&keywords=')\n",
    "            else:\n",
    "                r = ''\n",
    "                while r == '':\n",
    "                    try:\n",
    "                        r = requests.get(f'https://www.rightmove.co.uk/property-for-sale/find.html?locationIdentifier={station}&maxBedrooms={max_beds}&minBedrooms={min_beds}&radius={radius}&sortType=6&index={i*24}&propertyTypes=detached%2Cflat%2Csemi-detached%2Cterraced&maxDaysSinceAdded={days_since_added}&includeSSTC=false&mustHave=&dontShow=&furnishTypes=&keywords=')\n",
    "                        break\n",
    "                    except:\n",
    "                        print(f'Connection refused by the server on page {i+1}... sleeping for 3 seconds')\n",
    "                        time.sleep(3)\n",
    "                        print(\"Was a nice sleep, now let me continue...\")\n",
    "                        continue\n",
    "\n",
    "            soup = BeautifulSoup(r.text, 'lxml')\n",
    "            apartments = soup.find_all(\"div\", class_=\"l-searchResult is-list\")\n",
    "            \n",
    "            for j in range(len(apartments)):\n",
    "\n",
    "                # tracks which apartment we are on in the page\n",
    "                apartment_no = apartments[j]\n",
    "\n",
    "                # append link\n",
    "                apartment_info = apartment_no.find(\"a\", class_=\"propertyCard-link\")\n",
    "                link = \"https://www.rightmove.co.uk\" + apartment_info.attrs[\"href\"]\n",
    "                all_apartment_links.append(link)\n",
    "\n",
    "                # append price\n",
    "                price = (\n",
    "                    apartment_no.find(\"div\", class_=\"propertyCard-priceValue\")\n",
    "                    .get_text()\n",
    "                    .strip()\n",
    "                )\n",
    "                all_price.append(int(price.replace(\",\",\"\").replace(\"£\",\"\")))\n",
    "\n",
    "                # append featured listing indicator\n",
    "                featured = (\n",
    "                    apartment_no.find(\"div\", class_=\"propertyCard-moreInfoFeaturedTitle\")\n",
    "                    .get_text()\n",
    "                )\n",
    "                if len(featured) > 0:\n",
    "                    featured = 1\n",
    "                else:\n",
    "                    featured = 0\n",
    "                all_featured.append(featured)\n",
    "                \n",
    "                # append date\n",
    "                dt_string = datetime.now().strftime(\"%d/%m/%Y %H:%M\")\n",
    "                all_datetime.append(dt_string)\n",
    " \n",
    "    \n",
    "    ## Secondary scraper for 0.5 mile radius station\n",
    "\n",
    "    r= requests.get(f'https://www.rightmove.co.uk/property-for-sale/find.html?locationIdentifier=STATION%5E6380&maxBedrooms={max_beds}&minBedrooms={min_beds}&radius=0.5&sortType=6&propertyTypes=detached%2Cflat%2Csemi-detached%2Cterraced&maxDaysSinceAdded={days_since_added}&includeSSTC=false&mustHave=&dontShow=&furnishTypes=&keywords=')\n",
    "    soup = BeautifulSoup(r.text, 'lxml')\n",
    "\n",
    "    apartments = soup.find_all(\"div\", class_=\"l-searchResult is-list\")\n",
    "\n",
    "    for j in range(len(apartments)):\n",
    "\n",
    "        # tracks which apartment we are on in the page\n",
    "        apartment_no = apartments[j]\n",
    "\n",
    "        # append link\n",
    "        apartment_info = apartment_no.find(\"a\", class_=\"propertyCard-link\")\n",
    "        link = \"https://www.rightmove.co.uk\" + apartment_info.attrs[\"href\"]\n",
    "        all_apartment_links.append(link)\n",
    "\n",
    "        # append price\n",
    "        price = (\n",
    "            apartment_no.find(\"div\", class_=\"propertyCard-priceValue\")\n",
    "            .get_text()\n",
    "            .strip()\n",
    "        )\n",
    "        all_price.append(int(price.replace(\",\",\"\").replace(\"£\",\"\")))\n",
    "        \n",
    "        # append featured listing indicator\n",
    "        featured = (\n",
    "            apartment_no.find(\"div\", class_=\"propertyCard-moreInfoFeaturedTitle\")\n",
    "            .get_text()\n",
    "        )\n",
    "        if len(featured) > 0:\n",
    "            featured = 1\n",
    "        else:\n",
    "            featured = 0\n",
    "        all_featured.append(featured)\n",
    "        \n",
    "        # append date\n",
    "        dt_string = datetime.now().strftime(\"%d/%m/%Y %H:%M\")\n",
    "        all_datetime.append(dt_string)\n",
    "    \n",
    "    #remove_indices = [0,25]\n",
    "    #all_apartment_links = [i for j, i in enumerate(all_apartment_links) if j not in remove_indices]\n",
    "    #all_price = [i for j, i in enumerate(all_price) if j not in remove_indices]\n",
    "    #all_id_no = [i for j, i in enumerate(all_id_no) if j not in remove_indices]\n",
    "    \n",
    "    return r.ok, all_apartment_links, all_datetime, all_price, all_featured"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
